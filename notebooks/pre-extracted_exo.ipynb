{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dada623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3043bb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "898858eb-8583-468e-8ce9-99958f7285b8",
       "rows": [
        [
         "0",
         "38T9C",
         "c141",
         "1.9",
         "7.4"
        ],
        [
         "1",
         "38T9C",
         "c061",
         "0.0",
         "20.5"
        ],
        [
         "2",
         "38T9C",
         "c006",
         "6.4",
         "12.5"
        ],
        [
         "3",
         "38T9C",
         "c118",
         "5.5",
         "20.6"
        ],
        [
         "4",
         "38T9C",
         "c156",
         "8.9",
         "14.5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>class</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38T9C</td>\n",
       "      <td>c141</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38T9C</td>\n",
       "      <td>c061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38T9C</td>\n",
       "      <td>c006</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38T9C</td>\n",
       "      <td>c118</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38T9C</td>\n",
       "      <td>c156</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video class  start   end\n",
       "0  38T9C  c141    1.9   7.4\n",
       "1  38T9C  c061    0.0  20.5\n",
       "2  38T9C  c006    6.4  12.5\n",
       "3  38T9C  c118    5.5  20.6\n",
       "4  38T9C  c156    8.9  14.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df = pd.read_csv('E:\\MSc Data Science\\Third term\\Research Project\\general\\charade\\CharadesEgo\\CharadesEgo_v1_train_only3rd.csv')\n",
    "\n",
    "rows = []\n",
    "for _, r in anno_df.iterrows():\n",
    "  vid = r['charades_video']\n",
    "  actions = r['actions']\n",
    "  if (isinstance(actions, str)):\n",
    "    for trip in actions.split(';'):\n",
    "      cls, st, en = trip.split()\n",
    "      rows.append({'video': vid, 'class': cls, 'start': float(st), 'end': float(en)})\n",
    "\n",
    "all_actions = pd.DataFrame(rows)\n",
    "\n",
    "all_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a216d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9848\n",
      "2376\n",
      "Found 2375 videos in both annotations and features:\n"
     ]
    }
   ],
   "source": [
    "# Extract the raw video IDs (without the 'EGO' suffix)\n",
    "anno_ids = set(anno_df[\"charades_video\"])\n",
    "\n",
    "# List all .npy files in the features folder\n",
    "feat_root = \"E:\\MSc Data Science\\Third term\\Research Project\\general\\charade\\Charades_v1_features_vgg_flow_stride4\"\n",
    "feat_ids = {\n",
    "    os.path.splitext(fname)[0]\n",
    "    for fname in os.listdir(feat_root)\n",
    "    if fname.endswith(\".npy\")\n",
    "}\n",
    "\n",
    "print(len(feat_ids))\n",
    "print(len(anno_ids))\n",
    "\n",
    "\n",
    "# Compute intersection\n",
    "common_ids = sorted(anno_ids & feat_ids)\n",
    "\n",
    "print(f\"Found {len(common_ids)} videos in both annotations and features:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738a99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_actions = [\"c049\", \"c050\", \"c051\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ce2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = all_actions[(all_actions['class'].isin(filtered_actions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05e7e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "66a68596-dbba-49a8-8104-f9f71ed0211e",
       "rows": [
        [
         "248",
         "H9U38",
         "c051",
         "0.0",
         "25.1"
        ],
        [
         "468",
         "ZGHLY",
         "c051",
         "0.3",
         "23.38"
        ],
        [
         "469",
         "ZGHLY",
         "c049",
         "8.8",
         "14.8"
        ],
        [
         "881",
         "E27NK",
         "c051",
         "0.0",
         "11.9"
        ],
        [
         "911",
         "O5D7S",
         "c051",
         "0.0",
         "28.9"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>class</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>H9U38</td>\n",
       "      <td>c051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>ZGHLY</td>\n",
       "      <td>c051</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>ZGHLY</td>\n",
       "      <td>c049</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>E27NK</td>\n",
       "      <td>c051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>O5D7S</td>\n",
       "      <td>c051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video class  start    end\n",
       "248  H9U38  c051    0.0  25.10\n",
       "468  ZGHLY  c051    0.3  23.38\n",
       "469  ZGHLY  c049    8.8  14.80\n",
       "881  E27NK  c051    0.0  11.90\n",
       "911  O5D7S  c051    0.0  28.90"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(filtered.shape)\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b697ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c049': 0, 'c050': 1, 'c051': 2}\n"
     ]
    }
   ],
   "source": [
    "cls2idx = {c:i for i,c in enumerate(filtered_actions)}\n",
    "print(cls2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae40645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharadesExoFeatureTAL(Dataset):\n",
    "    def __init__(self, annots, feat_root, clip_len=48, stride=12, fps=24):\n",
    "        self.clip_len = clip_len\n",
    "        self.stride = stride\n",
    "        self.fps = fps\n",
    "        self.feat_root = feat_root\n",
    "        self.samples = []\n",
    "\n",
    "        for _, row in annots.iterrows():\n",
    "            vid, cls, st, en = row[\"video\"], row[\"class\"], row[\"start\"], row[\"end\"]\n",
    "\n",
    "            if type(vid) is not str:\n",
    "                continue\n",
    "\n",
    "            exo_feat_path = os.path.join(feat_root, vid + \".npy\")\n",
    "            if not os.path.isfile(exo_feat_path):\n",
    "                continue  # skip if feature file missing\n",
    "\n",
    "            # map times to feature indices (stride=4)\n",
    "            start_f = int(st * fps / 4)\n",
    "            end_f = int(en * fps / 4)\n",
    "\n",
    "            for f0 in range(start_f, end_f - clip_len + 1, stride):\n",
    "                self.samples.append(\n",
    "                    {\"exo_path\": exo_feat_path, \"start_idx\": f0, \"label\": cls2idx[cls]}\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        feats = np.load(s[\"exo_path\"])  # shape: (T_total, D)\n",
    "        clip = feats[s[\"start_idx\"] : s[\"start_idx\"] + self.clip_len]\n",
    "\n",
    "        if clip.shape[0] < self.clip_len:\n",
    "            pad_len = self.clip_len - clip.shape[0]\n",
    "            pad = np.zeros((pad_len, clip.shape[1]), dtype=clip.dtype)\n",
    "            clip = np.concatenate([clip, pad], axis=0)\n",
    "\n",
    "        clip = torch.from_numpy(clip.T).float()  # (D, clip_len)\n",
    "        return clip, s[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4972d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExoOnlyFeatModel(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes):\n",
    "        super().__init__()\n",
    "        # temporal averaging over feature frames\n",
    "        self.avg = lambda x: x.mean(dim=2)  # x: (B, D, T) -> (B, D)\n",
    "        self.fc  = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, D, T)\n",
    "        x = self.avg(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f9d39ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9849"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('Charades_v1_features_vgg_flow_stride4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "35dff0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 1.0058\n",
      "Epoch 2 loss: 0.8596\n",
      "Epoch 3 loss: 0.7567\n",
      "Epoch 4 loss: 0.6733\n",
      "Epoch 5 loss: 0.6150\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ds = CharadesExoFeatureTAL(filtered, feat_root='Charades_v1_features_vgg_flow_stride4')\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "\n",
    "# infer feat_dim from first batch\n",
    "exo_b, lbl_b = next(iter(loader))\n",
    "feat_dim = exo_b.shape[1]\n",
    "\n",
    "model = ExoOnlyFeatModel(feat_dim, num_classes=len(filtered_actions)).to(device)\n",
    "opt   = optim.Adam(model.parameters(), lr=1e-4)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for exo, labels in loader:\n",
    "        # exo: (B, D, T), labels: (B,)\n",
    "        exo, labels = exo.to(device), labels.to(device)\n",
    "        logits       = model(exo)\n",
    "        loss         = crit(logits, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} loss: {total_loss/len(loader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
